# Voice Assistant v2 - Lightweight Offline Voice Assistant

## Overview
A redesigned voice assistant optimized for:
- âœ… **Single speaker isolation** in crowded environments
- âœ… **100% offline operation** - no internet required
- âœ… **Low RAM usage** (~4-5GB) for mini PCs with 6GB RAM
- âœ… **Reliable audio pipeline** with noise reduction

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           VOICE ASSISTANT v2                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Audio     â”‚â”€â”€â”€â–¶â”‚  Speaker Isolation  â”‚â”€â”€â”€â–¶â”‚   Speech Recognition    â”‚  â”‚
â”‚  â”‚   Input     â”‚    â”‚  (Noise Reduction)  â”‚    â”‚        (STT)            â”‚  â”‚
â”‚  â”‚             â”‚    â”‚                     â”‚    â”‚                         â”‚  â”‚
â”‚  â”‚ â€¢ Mic Input â”‚    â”‚ â€¢ Beamforming       â”‚    â”‚ â€¢ faster-whisper tiny   â”‚  â”‚
â”‚  â”‚ â€¢ 16kHz     â”‚    â”‚ â€¢ Noise Gate        â”‚    â”‚ â€¢ int8 quantized        â”‚  â”‚
â”‚  â”‚ â€¢ Mono      â”‚    â”‚ â€¢ VAD Filtering     â”‚    â”‚ â€¢ CPU optimized         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                            â”‚                â”‚
â”‚                                                            â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Audio     â”‚â—€â”€â”€â”€â”‚     Text-to-Speech  â”‚â—€â”€â”€â”€â”‚   Language Model        â”‚  â”‚
â”‚  â”‚   Output    â”‚    â”‚        (TTS)        â”‚    â”‚       (LLM)             â”‚  â”‚
â”‚  â”‚             â”‚    â”‚                     â”‚    â”‚                         â”‚  â”‚
â”‚  â”‚ â€¢ Speaker   â”‚    â”‚ â€¢ Piper TTS         â”‚    â”‚ â€¢ llama.cpp             â”‚  â”‚
â”‚  â”‚ â€¢ 22kHz     â”‚    â”‚ â€¢ ONNX optimized    â”‚    â”‚ â€¢ Q4_K_M quantized      â”‚  â”‚
â”‚  â”‚             â”‚    â”‚ â€¢ ~50MB model       â”‚    â”‚ â€¢ 1-3B params           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Folder Structure

```
voice_assistant_v2/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ STEP_BY_STEP_GUIDE.md    # Detailed implementation guide
â”œâ”€â”€ requirements.txt          # Minimal dependencies
â”œâ”€â”€ .env.example             # Configuration template
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py          # Centralized configuration
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_input.py       # Step 1: Microphone capture
â”‚   â”œâ”€â”€ noise_reduction.py   # Step 2: Noise gate + filtering
â”‚   â”œâ”€â”€ speaker_isolation.py # Step 3: Target speaker detection
â”‚   â”œâ”€â”€ vad.py               # Step 4: Voice Activity Detection
â”‚   â”œâ”€â”€ stt.py               # Step 5: Speech-to-Text
â”‚   â”œâ”€â”€ llm.py               # Step 6: Language Model
â”‚   â”œâ”€â”€ tts.py               # Step 7: Text-to-Speech
â”‚   â””â”€â”€ audio_output.py      # Step 8: Speaker output
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ orchestrator.py      # Main pipeline coordinator
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_utils.py       # Audio conversion helpers
â”‚   â”œâ”€â”€ ring_buffer.py       # Circular buffer for streaming
â”‚   â””â”€â”€ wake_word.py         # Optional: Wake word detection
â”‚
â”œâ”€â”€ models/                   # Model files (gitignored)
â”‚   â”œâ”€â”€ stt/                 # Whisper models
â”‚   â”œâ”€â”€ tts/                 # Piper voice models
â”‚   â””â”€â”€ llm/                 # GGUF LLM models
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_audio_input.py
    â”œâ”€â”€ test_noise_reduction.py
    â”œâ”€â”€ test_speaker_isolation.py
    â”œâ”€â”€ test_vad.py
    â”œâ”€â”€ test_stt.py
    â”œâ”€â”€ test_tts.py
    â””â”€â”€ test_full_pipeline.py
```

---

## Key Improvements Over v1

| Feature | v1 (Current) | v2 (New) |
|---------|--------------|----------|
| Noise handling | Basic VAD only | Noise gate + spectral filtering |
| Crowded places | Picks up all voices | Speaker isolation via proximity/volume |
| RAM usage | ~5-6GB | ~4GB optimized |
| Wake word | None | Optional "Hey Assistant" |
| Reliability | Basic error handling | Robust with fallbacks |
| Offline | Yes | Yes (fully offline) |

---

## Hardware Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| RAM | 4GB free | 6GB total |
| CPU | 4 cores | 6+ cores |
| Storage | 2GB | 5GB |
| Microphone | Any USB | Directional mic |

---

## Quick Start

```bash
# 1. Create virtual environment
python -m venv venv
source venv/bin/activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Download models (run once)
python scripts/download_models.py

# 4. Configure
cp .env.example .env
# Edit .env with your settings

# 5. Run
python -m pipeline.orchestrator
```

---

## Next Steps

ğŸ‘‰ **Read [STEP_BY_STEP_GUIDE.md](STEP_BY_STEP_GUIDE.md) for detailed implementation instructions**
